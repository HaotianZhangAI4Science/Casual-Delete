{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "from utils.pdb_parser import PDBProtein\n",
    "import os.path as osp\n",
    "import sys\n",
    "# sys.path.append('/home/haotian/Molecule_Generation/MG/Flex-SBDD')\n",
    "from tqdm import tqdm\n",
    "from utils.data import ProteinLigandData, torchify_dict\n",
    "from utils.protein_ligand import parse_sdf_file, read_ply\n",
    "from utils.chem import read_sdf, read_pkl\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.transforms import Compose\n",
    "from rdkit import Chem\n",
    "from glob import glob\n",
    "from utils.chem import write_pkl, read_pkl, write_sdf\n",
    "\n",
    "from easydict import EasyDict\n",
    "from rdkit.Chem.rdMolAlign import CalcRMS\n",
    "\n",
    "def get_result(docked_sdf, ref_mol=None):\n",
    "    suppl = Chem.SDMolSupplier(docked_sdf,sanitize=False)\n",
    "    results = []\n",
    "    for i, mol in enumerate(suppl):\n",
    "        if mol is None:\n",
    "            continue\n",
    "        line = mol.GetProp('REMARK').splitlines()[0].split()[2:]\n",
    "        try:\n",
    "            rmsd = CalcRMS(ref_mol, mol)\n",
    "        except:\n",
    "            rmsd = np.nan\n",
    "        results.append(EasyDict({\n",
    "            'rdmol': mol,\n",
    "            'mode_id': i,\n",
    "            'affinity': float(line[0]),\n",
    "            'rmsd_lb': float(line[1]),\n",
    "            'rmsd_ub': float(line[2]),\n",
    "            'rmsd_ref': rmsd\n",
    "        }))\n",
    "    return results\n",
    "\n",
    "def checkatoms(mol, allowed_atoms=['C', 'N', 'O', 'F', 'P', 'S', 'Cl']):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for atom in mol.GetAtoms():\n",
    "        if atom.GetSymbol() not in allowed_atoms:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the protein-liagand pair files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the 2695 mols\n",
      "pkl file saved at ./casual_inference/index_list.pkl\n"
     ]
    }
   ],
   "source": [
    "surface_file = './causal_inference/4fny_protein_pocket_8.0.ply'\n",
    "ligand_files = glob('./causal_inference/SDF/*_out.sdf')\n",
    "\n",
    "index_list = []\n",
    "for ligand_file in ligand_files:\n",
    "    try:\n",
    "        mol = read_sdf(ligand_file)[0]\n",
    "        mol = Chem.RemoveHs(mol)\n",
    "        # write_sdf([mol], ligand_file) # write the sdf file without H, if you encounter the atomic error\n",
    "        if not checkatoms(mol):\n",
    "            continue\n",
    "        mol_impact = - torch.tensor(get_result(ligand_file)[0]['affinity'])\n",
    "        index_list.append((surface_file, ligand_file, mol_impact)) # change the label to your own\n",
    "    except:\n",
    "        pass\n",
    "print('Get the',len(index_list), 'mols')\n",
    "    \n",
    "write_pkl(index_list, './causal_inference/index_list.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the LMDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2695/2695 [01:25<00:00, 31.68it/s]\n"
     ]
    }
   ],
   "source": [
    "index = read_pkl('./causal_inference/index_list.pkl')\n",
    "\n",
    "processed_path = './data/causal_inference_data.lmdb' \n",
    "db = lmdb.open(\n",
    "    processed_path,\n",
    "    map_size=10*(1024*1024*1024),   # 10GB\n",
    "    create=True,\n",
    "    subdir=False,\n",
    "    readonly=False, # Writable\n",
    ")\n",
    "\n",
    "num_skipped = 0\n",
    "with db.begin(write=True, buffers=True) as txn:\n",
    "    for i, (ply_file, sdf_file, mol_impact) in enumerate(tqdm(index)):\n",
    "        if ply_file is None: continue\n",
    "        try:\n",
    "            pocket_dict = read_ply(ply_file)\n",
    "            ligand_dict = parse_sdf_file(sdf_file)\n",
    "            data = ProteinLigandData.from_protein_ligand_dicts(\n",
    "                protein_dict=torchify_dict(pocket_dict),\n",
    "                ligand_dict=torchify_dict(ligand_dict),\n",
    "            )\n",
    "            data.mol_impact = mol_impact # change the label to your own\n",
    "            data.protein_filename = ply_file\n",
    "            data.ligand_filename = sdf_file\n",
    "            data.mol = ligand_dict['mol']\n",
    "            txn.put(\n",
    "                key = str(i).encode(),\n",
    "                value = pickle.dumps(data)\n",
    "            )\n",
    "        except:\n",
    "            num_skipped += 1\n",
    "            if num_skipped%100 == 0:\n",
    "                print('Skipping (%d)' % (num_skipped, ))\n",
    "            continue\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transforms import *\n",
    "\n",
    "config_file = './configs/causual_inference.yml'\n",
    "config = load_config(config_file)\n",
    "\n",
    "protein_featurizer = FeaturizeProteinAtom()\n",
    "ligand_featurizer = FeaturizeLigandAtom()                   \n",
    "masking = get_mask(config.train.transform.mask)\n",
    "composer = AtomComposer(protein_featurizer.feature_dim, ligand_featurizer.feature_dim, config.model.encoder.knn)\n",
    "\n",
    "edge_sampler = EdgeSample(config.train.transform.edgesampler)\n",
    "cfg_ctr = config.train.transform.contrastive\n",
    "contrastive_sampler = ContrastiveSample(cfg_ctr.num_real, cfg_ctr.num_fake, cfg_ctr.pos_real_std, cfg_ctr.pos_fake_std, config.model.field.knn)\n",
    "\n",
    "transform = Compose([\n",
    "    RefineData(),\n",
    "    LigandCountNeighbors(),\n",
    "    protein_featurizer,\n",
    "    ligand_featurizer,\n",
    "    masking,\n",
    "    composer,\n",
    "\n",
    "    FocalBuilder(),\n",
    "    edge_sampler,\n",
    "    contrastive_sampler,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007154226303100586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2695,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6721fdd700db47b3ac7b66e0cc8c57df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 23\n",
      "530 37\n",
      "795 4\n",
      "1050 25\n",
      "1179 28\n",
      "2580 empty range for randrange() (0, 0, 0)\n",
      "saved name2id at ./data/causal_inference_data_name2id.pt\n",
      "Get 2689 mols\n"
     ]
    }
   ],
   "source": [
    "name2id_path = './data/causal_inference_data_name2id.pt'\n",
    "processed_path = './data/causal_inference_data.lmdb'\n",
    "\n",
    "db = lmdb.open(\n",
    "        processed_path,\n",
    "        map_size=10*(1024*1024*1024),   # 10GB\n",
    "        create=False,\n",
    "        subdir=False,\n",
    "        readonly=True,\n",
    "        lock=False,\n",
    "        readahead=False,\n",
    "        meminit=False,\n",
    "    )\n",
    "with db.begin() as txn:\n",
    "    keys = list(txn.cursor().iternext(values=False))\n",
    "    \n",
    "name2id = {}\n",
    "for i in tqdm(range(len(keys))):\n",
    "    try:\n",
    "\n",
    "        for _ in range(20):\n",
    "            data = transform(pickle.loads(db.begin().get(keys[i])))\n",
    "\n",
    "        name = (data['protein_filename'], data['ligand_filename'])\n",
    "        name2id[name] = i\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        continue\n",
    "\n",
    "torch.save(name2id, name2id_path)\n",
    "print('saved name2id at {}'.format(name2id_path))\n",
    "print('Get',len(name2id.keys()), 'mols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = torch.load(name2id_path)\n",
    "name2id_list = list(name2id.keys())\n",
    "\n",
    "split_name = {}\n",
    "split_name['train'] = []\n",
    "for i in range(len(name2id.keys())):\n",
    "    split_name['train'].append(name2id_list[i])\n",
    "split_name['val'] = split_name['train'][:20] \n",
    "torch.save(split_name, './data/causal_inference_data_split_name.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carbon_copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
